{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import loader as loader\n",
    "from train import *\n",
    "from loader import *\n",
    "from model import NERModel\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.ArgumentParser()\n",
    "\n",
    "args.add_argument(\"--dataset\", default=\"wnut16\", choices=[\"GMB\", \"wnut16\"])\n",
    "args.add_argument(\"--use_gpu\", action=\"store_true\", default=False)\n",
    "args.add_argument(\"--word_dim\", type=int, default=100)\n",
    "args.add_argument(\"--pre_emb\", default=\"src/glove.6B/glove.6B.300d.word2vec\")\n",
    "args.add_argument(\"--lstm_dim\", type=int, default=300)\n",
    "args.add_argument(\"--epoch\", type=int, default=10)\n",
    "args.add_argument(\"--use_crf\", action=\"store_true\", default=True)\n",
    "args.add_argument(\"--batch_size\", type=int, default=32)\n",
    "args.add_argument(\"--num_layers\", type=int, default=2)\n",
    "args.add_argument(\"--num_workers\", type=int, default=4)\n",
    "args = args.parse_args([])\n",
    "\n",
    "args.train = \"../released/ner/\" + args.dataset + \"/train\"\n",
    "args.test = \"../released/ner/\" + args.dataset + \"/test\"\n",
    "args.dev = \"../released/ner/\" + args.dataset + \"/dev\"\n",
    "use_gpu = args.use_gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "\n",
    "train_sentences = loader.load_sentences(args.train)\n",
    "dev_sentences = loader.load_sentences(args.dev)\n",
    "test_sentences = loader.load_sentences(args.test)\n",
    "\n",
    "word2id, id2word = word_mapping(\n",
    "    train_sentences, test_sentences, dev_sentences)\n",
    "tag2id, id2tag = tag_mapping(\n",
    "    train_sentences, test_sentences, dev_sentences)\n",
    "\n",
    "train_set = NERDataset(train_sentences, word2id, tag2id)\n",
    "test_set = NERDataset(test_sentences, word2id, tag2id)\n",
    "dev_set = NERDataset(dev_sentences, word2id, tag2id)\n",
    "\n",
    "train_data = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers,\n",
    "                        collate_fn=train_set.collate_fn)\n",
    "\n",
    "test_data = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers,\n",
    "                        collate_fn=test_set.collate_fn)\n",
    "\n",
    "dev_data = DataLoader(dev_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers,\n",
    "                        collate_fn=dev_set.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 pretrained embeddings.\n"
     ]
    }
   ],
   "source": [
    "all_word_embeds = {}\n",
    "word_dim = args.word_dim\n",
    "if args.pre_emb:\n",
    "    for i, line in enumerate(open(args.pre_emb, \"r\", encoding=\"utf-8\")):\n",
    "        s = line.strip().split()\n",
    "        word_dim = len(s) - 1\n",
    "        all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "    print(\"Loaded %i pretrained embeddings.\" % len(all_word_embeds))\n",
    "\n",
    "word_embeds = np.random.uniform(-np.sqrt(0.06),\n",
    "                                np.sqrt(0.06), (len(word2id), word_dim))\n",
    "\n",
    "for w in word2id:\n",
    "    if w in all_word_embeds:\n",
    "        word_embeds[word2id[w]] = all_word_embeds[w]\n",
    "    elif w.lower() in all_word_embeds:\n",
    "        word_embeds[word2id[w]] = all_word_embeds[w.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(\n",
    "        vocab_size=len(word2id),\n",
    "        tag_to_ix=tag2id,\n",
    "        embedding_dim=word_dim,\n",
    "        hidden_dim=args.lstm_dim,\n",
    "        num_laters=args.num_layers,\n",
    "        pre_word_embeds=word_embeds,\n",
    "        use_gpu=args.use_gpu,\n",
    "        use_crf=args.use_crf,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [01:02,  1.01it/s]\n",
      "63it [01:02,  1.01it/s]\n",
      "63it [01:10,  1.11s/it]\n",
      "11it [00:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9554.894477539063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [01:05,  1.03s/it]\n",
      "63it [01:04,  1.02s/it]\n",
      "63it [01:02,  1.01it/s]\n",
      "22it [00:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9554.894477539063, 9472.584164770507]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [01:05,  1.04s/it]\n",
      "63it [01:03,  1.01s/it]\n",
      "63it [00:58,  1.07it/s]\n",
      "33it [00:22,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9554.894477539063, 9472.584164770507, 9320.914097581664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [01:02,  1.02it/s]\n",
      "63it [01:02,  1.01it/s]\n",
      "63it [01:02,  1.01it/s]\n",
      "43it [00:29,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9554.894477539063, 9472.584164770507, 9320.914097581664, 9202.040752128532]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:48,  1.14s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NERModel' object has no attribute 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/dhavalgarg/Downloads/Assignment files/NLP/released/part2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhavalgarg/Downloads/Assignment%20files/NLP/released/part2.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhavalgarg/Downloads/Assignment%20files/NLP/released/part2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dhavalgarg/Downloads/Assignment%20files/NLP/released/part2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train(model, args\u001b[39m.\u001b[39;49mepoch, train_data, dev_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dhavalgarg/Downloads/Assignment%20files/NLP/released/part2.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         test_data, use_gpu\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49muse_gpu, id_to_tag\u001b[39m=\u001b[39;49mid2tag)\n",
      "File \u001b[0;32m~/Downloads/Assignment files/NLP/released/train.py:158\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epochs, train_data, dev_data, test_data, use_gpu, id_to_tag)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m (count \u001b[39m%\u001b[39m (eval_every) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m count \u001b[39m>\u001b[39m (eval_every \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m) \u001b[39mor\u001b[39;00m count \u001b[39m%\u001b[39m (eval_every \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m count \u001b[39m<\u001b[39m\n\u001b[1;32m    156\u001b[0m         (eval_every \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m)):\n\u001b[1;32m    157\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 158\u001b[0m     best_test_F, new_test_F, _ \u001b[39m=\u001b[39m evaluating(\n\u001b[1;32m    159\u001b[0m         model, test_data, best_test_F, use_gpu, id_to_tag)\n\u001b[1;32m    160\u001b[0m     best_dev_F, new_dev_F, save \u001b[39m=\u001b[39m evaluating(\n\u001b[1;32m    161\u001b[0m         model, dev_data, best_dev_F, use_gpu, id_to_tag)\n\u001b[1;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m save:\n",
      "File \u001b[0;32m~/Downloads/Assignment files/NLP/released/train.py:52\u001b[0m, in \u001b[0;36mevaluating\u001b[0;34m(model, datas, best_F, use_gpu, id_to_tag)\u001b[0m\n\u001b[1;32m     50\u001b[0m     val, out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39minference(word_ids\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     val, out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minference(word_ids)\n\u001b[1;32m     54\u001b[0m predicted_id \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mYou need to convert the predicted ids to tags and then compare them with the gold tags here.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mNotice that the model gives you the predicted ids for the whole sentence, but you only need to compare the valid tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Assignment files/NLP/released/model.py:130\u001b[0m, in \u001b[0;36mNERModel.inference\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    127\u001b[0m lstm_feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_features(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embedding(sentence))\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_crf:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# Use Viterbi decode for inference\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     scores, tag_seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrf\u001b[39m.\u001b[39minference(lstm_feats, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask)\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m \u001b[39m# Use argmax to get the predicted tags\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     scores, tag_seq \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(lstm_feats, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NERModel' object has no attribute 'mask'"
     ]
    }
   ],
   "source": [
    "if args.use_gpu:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "train(model, args.epoch, train_data, dev_data,\n",
    "        test_data, use_gpu=args.use_gpu, id_to_tag=id2tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bec4ffc65abad1b1b7862a0abc19e670057a4673581208a7c61a208b38b7ad18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
